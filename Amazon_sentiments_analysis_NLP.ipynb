{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-grsWO_vbJJ6"
      },
      "source": [
        "#Amazon sentiment Analysis\n",
        "The analysis focuses on determining or predicitng wherether a sentiment is negative or positive using Natural Language Processing (NLP) algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX0jTLKFbp7j"
      },
      "source": [
        "## Check for mismatchlibraries dependecies for the analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUV-k3rgIvAH",
        "outputId": "ecb9d627-30bd-4285-e49a-3426b2510848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No broken requirements found.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TSgPV_AbEm6"
      },
      "source": [
        "## Import the neccessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzQjbIiuaXqx",
        "outputId": "50e0c48a-7b28-45b1-c759-e60134ea17f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to ./data/raw...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to ./data/raw...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to ./data/raw...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from pickle import dump\n",
        "from pickle import load\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "# Set the NLTK data directory\n",
        "nltk_data_dir = './data/raw'\n",
        "os.makedirs(nltk_data_dir, exist_ok=True)\n",
        "nltk.data.path.append(nltk_data_dir)\n",
        "\n",
        "# Download the required NLTK resources to the specified directory\n",
        "nltk.download('stopwords', download_dir=nltk_data_dir)\n",
        "nltk.download('punkt', download_dir=nltk_data_dir)\n",
        "nltk.download('punkt_tab', download_dir=nltk_data_dir)\n",
        "import tensorflow as tf\n",
        "\n",
        "# from  .keras.preprocessing.sequence import pad_sequences\n",
        "# from tensorflow.keras.layers import LSTM, Input, Dense, Embedding, TimeDistributed\n",
        "# from tensorflow.keras.models import Sequential\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Tl1bsVH6dOIZ"
      },
      "outputs": [],
      "source": [
        "# Path and regex\n",
        "path = \"./data/domain_sentiment_data/sorted_data_acl/\"\n",
        "regex_review = re.compile(\"<review_text>.+?</review_text>\", flags=re.DOTALL)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_sentence(sentence: str) -> list:\n",
        "    tags = re.compile(\"(<review_text>|<\\/review_text>)\")\n",
        "    sentence = re.sub(tags, '', sentence)\n",
        "\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    email_urls = re.compile(r\"(http\\S+|www\\.\\S+|[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,})\")\n",
        "    sentence = re.sub(email_urls, '', sentence)\n",
        "\n",
        "    sentence = sentence.replace('@', 'a')\n",
        "\n",
        "    punc = re.compile(r\"[^\\w\\s]\")\n",
        "    sentence = re.sub(punc, '', sentence)\n",
        "\n",
        "    sentence = word_tokenize(sentence)\n",
        "    # Use the global stop_words set\n",
        "    sentence = [word for word in sentence if word not in stop_words]\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKmlPxpWdWCl",
        "outputId": "f3f5c33c-d2fa-4e58-a63b-c111419c071a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading Train Data (multithreaded)\n",
            "Reading Test Data (multithreaded)\n",
            "Training samples: 6000, Testing samples: 2000\n"
          ]
        }
      ],
      "source": [
        "import threading\n",
        "lock = threading.Lock()\n",
        "\n",
        "def process_reviews(file_path, label, target_x, target_y, regex):\n",
        "    with open(file_path, 'r') as f:\n",
        "        content = f.read()\n",
        "    reviews = re.findall(regex, content)\n",
        "    for sentence in reviews:\n",
        "        cleaned = clean_sentence(sentence)\n",
        "        with lock:\n",
        "            target_x.append(cleaned)\n",
        "            target_y.append(label)\n",
        "\n",
        "# Shared lists\n",
        "x_train, y_train = [], []\n",
        "x_test, y_test = [], []\n",
        "\n",
        "def load_multithreaded_data(folders, is_train=True):\n",
        "    threads = []\n",
        "    for folder in folders:\n",
        "        base_x, base_y = (x_train, y_train) if is_train else (x_test, y_test)\n",
        "\n",
        "        neg_path = f\"{path}{folder}/negative.review\"\n",
        "        pos_path = f\"{path}{folder}/positive.review\"\n",
        "\n",
        "        t1 = threading.Thread(target=process_reviews, args=(neg_path, 0, base_x, base_y, regex_review))\n",
        "        t2 = threading.Thread(target=process_reviews, args=(pos_path, 1, base_x, base_y, regex_review))\n",
        "\n",
        "        t1.start()\n",
        "        t2.start()\n",
        "\n",
        "        threads.extend([t1, t2])\n",
        "\n",
        "    for t in threads:\n",
        "        t.join()\n",
        "\n",
        "# Read and process data\n",
        "print('Reading Train Data (multithreaded)')\n",
        "load_multithreaded_data([\"books\", \"dvd\", \"electronics\"], is_train=True)\n",
        "\n",
        "print('Reading Test Data (multithreaded)')\n",
        "load_multithreaded_data([\"kitchen_&_housewares\"], is_train=False)\n",
        "\n",
        "print(f\"Training samples: {len(x_train)}, Testing samples: {len(x_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wi1ShY0Tcp1"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "os.makedirs('./data/model/amazon', exist_ok=True)\n",
        "\n",
        "with open('./data/model/amazon/x_train.pkl', 'wb') as temp_file:\n",
        "    dump(x_train, temp_file)\n",
        "\n",
        "with open('./data/model/amazon/y_train.pkl', 'wb') as temp_file:\n",
        "    dump(y_train, temp_file)\n",
        "\n",
        "with open('./data/model/amazon/x_test.pkl', 'wb') as temp_file:\n",
        "    dump(x_test, temp_file)\n",
        "\n",
        "with open('./data/model/amazon/y_test.pkl', 'wb') as temp_file:\n",
        "    dump(y_test, temp_file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ztDqHPhNhElu",
        "outputId": "7311a68d-7691-482b-a69a-c1d346b8ce26"
      },
      "outputs": [],
      "source": [
        "# Loading them\n",
        "\n",
        "temp_file = open('./data/model/amazon/x_train.pkl', 'rb')\n",
        "x_train = load(temp_file)\n",
        "temp_file.close()\n",
        "\n",
        "temp_file = open('./data/model/amazon/y_train.pkl', 'rb')\n",
        "y_train = load(temp_file)\n",
        "temp_file.close()\n",
        "\n",
        "temp_file = open('./data/model/amazon/x_test.pkl', 'rb')\n",
        "x_test = load(temp_file)\n",
        "temp_file.close()\n",
        "\n",
        "temp_file = open('./data/model/amazon/y_test.pkl', 'rb')\n",
        "y_test = load(temp_file)\n",
        "temp_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "crWyWbqkVpoa",
        "outputId": "4efed1c8-ce85-48f6-fd3a-24fe90af7319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max size: 1834\n",
            "Min size: 1\n",
            "Top 10 sizes: [573, 576, 581, 600, 600, 602, 617, 618, 628, 641, 675, 675, 682, 693, 698, 739, 755, 818, 1209, 1834]\n",
            "From  0.0 to 20.0 : 931.0\n",
            "From  20.0 to 40.0 : 1396.0\n",
            "From  40.0 to 60.0 : 1136.0\n",
            "From  60.0 to 80.0 : 675.0\n",
            "From  80.0 to 100.0 : 467.0\n",
            "From  100.0 to 120.0 : 313.0\n",
            "From  120.0 to 140.0 : 237.0\n",
            "From  140.0 to 160.0 : 155.0\n",
            "From  160.0 to 180.0 : 117.0\n",
            "From  180.0 to 200.0 : 105.0\n",
            "From  200.0 to 300.0 : 309.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Some investigations\n",
        "lengths = [len(sentence) for sentence in x_train]\n",
        "lengths.sort()\n",
        "print(\"Max size:\", max(lengths))\n",
        "print(\"Min size:\", min(lengths))\n",
        "print(\"Top 10 sizes:\",lengths[-20:])\n",
        "counts,bins,_ = plt.hist(lengths,bins=[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 300, 2000])\n",
        "for i in range(len(counts)-1):\n",
        "  print('From ',bins[i],'to',bins[i+1],':',counts[i])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Most reviews are less than 100 words (4614), and 918 reviews are less than 200 but greater than 100\n",
        "# Lets take max sequence length as 125 (using weighted mean and neglecting reviews above 300 words)\n",
        "# or 175 if we took all review sizes into consideration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbwf5MU-WBNE",
        "outputId": "56bfa613-c6ae-4e4a-f2d7-3c72e6a4798d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size: 43101\n"
          ]
        }
      ],
      "source": [
        "# Get the vocab\n",
        "vocab = set()\n",
        "for sentence in x_train:\n",
        "  for word in sentence:\n",
        "    vocab.add(word)\n",
        "\n",
        "vocab.add('') # for dummy words, to avoid adding a word that has a meaning\n",
        "print(\"Vocab size:\", len(vocab))\n",
        "\n",
        "# Make a mapping betwween words and their IDs\n",
        "word2id = {word:id for  id, word in enumerate(vocab)}\n",
        "id2word = {id:word for  id, word in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9wCrkR85WEjj"
      },
      "outputs": [],
      "source": [
        "def encode_sentence(old_sentence):\n",
        "  encoded_sentence = []\n",
        "  dummy = word2id['']\n",
        "  for word in old_sentence:\n",
        "    try:\n",
        "      encoded_sentence.append(word2id[word])\n",
        "    except KeyError:\n",
        "      encoded_sentence.append(dummy) # the none char\n",
        "\n",
        "  return encoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6rsBrHWWGz-",
        "outputId": "c4f6ba35-b563-48df-9890-7c12001bfe4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Len train: 6000\n",
            "Len test: 2000\n"
          ]
        }
      ],
      "source": [
        "# Encoding train sentences\n",
        "x_train_encoded = []\n",
        "for sentence in x_train:\n",
        "  x_train_encoded.append(encode_sentence(sentence))\n",
        "\n",
        "# Encoding test sentences\n",
        "x_test_encoded = []\n",
        "for sentence in x_test:\n",
        "  x_test_encoded.append(encode_sentence(sentence))\n",
        "\n",
        "print(\"Len train:\", len(x_train_encoded))\n",
        "print(\"Len test:\", len(x_test_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3KHhymoWJVR",
        "outputId": "3462f5a0-1a38-4e79-f305-3e5311d88da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape:  (6000, 125)\n",
            "Test shape:  (2000, 125)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "MAX_SEQ_LEN = 125\n",
        "dummy = word2id['']\n",
        "# Padding train sentences\n",
        "x_train_padded = pad_sequences(x_train_encoded, maxlen=MAX_SEQ_LEN, dtype='int', padding='post', truncating='post', value=dummy)\n",
        "print(\"Train shape: \",x_train_padded.shape)\n",
        "\n",
        "# Padding test sentences\n",
        "x_test_padded = pad_sequences(x_test_encoded, maxlen=MAX_SEQ_LEN, dtype='int', padding='post', truncating='post', value=dummy)\n",
        "print(\"Test shape: \", x_test_padded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIpPqqK2WN4F",
        "outputId": "d069243a-b53e-445a-9f4c-e09fc65075ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 1)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Changing labels type and shape for training\n",
        "y_train = np.array(y_train)\n",
        "y_train = y_train.reshape((y_train.shape[0], 1))\n",
        "y_train.shape\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "y_test = y_test.reshape((y_test.shape[0], 1))\n",
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epNHaoOIYDQM",
        "outputId": "b181d0f9-b3ae-4539-8fa5-a198aa11b3fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 758.5/758.5MB downloaded\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('mohamed', 0.71284019947052),\n",
              " ('mostafa', 0.6895012259483337),\n",
              " ('ahmed', 0.6817302703857422),\n",
              " ('mohey', 0.6513986587524414),\n",
              " ('ahmadinejad', 0.6093316078186035),\n",
              " ('mohammed', 0.5743428468704224),\n",
              " ('youssef', 0.5647962689399719),\n",
              " ('morsi', 0.554459810256958),\n",
              " ('hassan', 0.5542215704917908),\n",
              " ('fouad', 0.5403571724891663)]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading the Word2Vec Model\n",
        "# glove-twitter-200 model was trained on 2B tweets\n",
        "# with a 1.2M vocab size\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "w2v = api.load('glove-twitter-200')\n",
        "w2v.most_similar(\"mahmoud\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-1FSLoOg2j5",
        "outputId": "f5c353a4-743a-4be6-9bf6-70f6ee7527bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(43101, 200)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create an embedding matrix for the embedding layer\n",
        "num_words = len(vocab)\n",
        "embed_size, = w2v['mahmoud'].shape\n",
        "embedding_matrix = np.zeros(shape=(num_words, embed_size))\n",
        "\n",
        "for word, id in word2id.items():\n",
        "  try:\n",
        "    embedding_matrix[id] = w2v[word]\n",
        "  except KeyError:\n",
        "    embedding_matrix[id] = np.zeros(embed_size)\n",
        "\n",
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "z61G2wsbjSAs",
        "outputId": "1b4bcdf7-f887-43f1-fbb6-7c23707e2652"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Rating\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"Rating\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,620,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,720</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │     \u001b[38;5;34m8,620,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │        \u001b[38;5;34m27,720\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m7,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,655,271</span> (33.02 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,655,271\u001b[0m (33.02 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,071</span> (137.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,071\u001b[0m (137.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,620,200</span> (32.88 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,620,200\u001b[0m (32.88 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.layers import LSTM, Input, Dense, Embedding, TimeDistributed\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "tf.keras.backend.clear_session() # Makes sure old model was deleted if exists\n",
        "\n",
        "# create model\n",
        "lstm_model = Sequential(name='Rating')\n",
        "\n",
        "lstm_model.add(Input(shape=(MAX_SEQ_LEN,), dtype='int32'))\n",
        "\n",
        "lstm_model.add(Embedding(input_dim = len(vocab),            # Vocabulary Size (number of unique words for training)\n",
        "                        output_dim = embed_size,            # Length of the vector for each word (embedding dimension)\n",
        "                        weights = [embedding_matrix],       # Send the needed glove-twitter-200 Weights\n",
        "                        trainable = False))\n",
        "\n",
        "lstm_model.add(LSTM(units = 30,\n",
        "                    return_sequences=True,\n",
        "                    # dropout=0.5,\n",
        "                    # recurrent_dropout=0.5\n",
        "                    )\n",
        "              )\n",
        "lstm_model.add(LSTM(units = 30,\n",
        "                    # return_sequences=True,\n",
        "                    # dropout=0.5,\n",
        "                    # recurrent_dropout=0.5\n",
        "                    )\n",
        "              )\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999),\n",
        "                   loss='binary_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "lstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "z1IrKf06ju4k"
      },
      "outputs": [],
      "source": [
        "train_data, train_labels = shuffle(x_train_padded, y_train, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmIs7X2Vjx4d",
        "outputId": "d54bc42b-c72f-4b52-dfd5-8a27763952b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "lstm_model.save(\"./sentiment_app/data/model/lstm_w_770.h5\",save_format=\"h5\")\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Fit the tokenizer on your training data if not already done\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([' '.join(sentence) for sentence in x_train])\n",
        "\n",
        "with open(\"./sentiment_app/data/model/tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl67RCYhj3jm",
        "outputId": "6fc40ec6-5ef3-4851-dfe0-a104e44ffdd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-05-05 12:52:06.769721: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.4999 - loss: 0.6929 - val_accuracy: 0.5250 - val_loss: 0.6940\n",
            "Epoch 2/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5146 - loss: 0.6919 - val_accuracy: 0.5175 - val_loss: 0.6932\n",
            "Epoch 3/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5108 - loss: 0.6905 - val_accuracy: 0.5242 - val_loss: 0.6917\n",
            "Epoch 4/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5311 - loss: 0.6893 - val_accuracy: 0.5283 - val_loss: 0.6899\n",
            "Epoch 5/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5265 - loss: 0.6874 - val_accuracy: 0.5358 - val_loss: 0.6862\n",
            "Epoch 6/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5424 - loss: 0.6828 - val_accuracy: 0.5350 - val_loss: 0.6796\n",
            "Epoch 7/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5599 - loss: 0.6729 - val_accuracy: 0.5983 - val_loss: 0.6648\n",
            "Epoch 8/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6639 - loss: 0.6452 - val_accuracy: 0.6558 - val_loss: 0.6278\n",
            "Epoch 9/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6901 - loss: 0.6043 - val_accuracy: 0.7158 - val_loss: 0.5846\n",
            "Epoch 10/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7125 - loss: 0.5870 - val_accuracy: 0.7183 - val_loss: 0.5789\n",
            "Epoch 11/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7266 - loss: 0.5723 - val_accuracy: 0.7367 - val_loss: 0.5610\n",
            "Epoch 12/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7487 - loss: 0.5407 - val_accuracy: 0.7417 - val_loss: 0.5516\n",
            "Epoch 13/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7496 - loss: 0.5366 - val_accuracy: 0.7492 - val_loss: 0.5432\n",
            "Epoch 14/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7633 - loss: 0.5296 - val_accuracy: 0.7458 - val_loss: 0.5387\n",
            "Epoch 15/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7662 - loss: 0.5179 - val_accuracy: 0.7483 - val_loss: 0.5362\n",
            "Epoch 16/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7791 - loss: 0.5052 - val_accuracy: 0.7500 - val_loss: 0.5385\n",
            "Epoch 17/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7655 - loss: 0.5179 - val_accuracy: 0.7583 - val_loss: 0.5325\n",
            "Epoch 18/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7886 - loss: 0.4851 - val_accuracy: 0.7533 - val_loss: 0.5264\n",
            "Epoch 19/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7868 - loss: 0.4896 - val_accuracy: 0.7683 - val_loss: 0.5234\n",
            "Epoch 20/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7961 - loss: 0.4789 - val_accuracy: 0.7625 - val_loss: 0.5146\n",
            "Epoch 21/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8104 - loss: 0.4620 - val_accuracy: 0.7675 - val_loss: 0.5163\n",
            "Epoch 22/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8022 - loss: 0.4672 - val_accuracy: 0.7658 - val_loss: 0.5081\n",
            "Epoch 23/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8077 - loss: 0.4616 - val_accuracy: 0.7675 - val_loss: 0.5032\n",
            "Epoch 24/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8202 - loss: 0.4448 - val_accuracy: 0.7692 - val_loss: 0.5121\n",
            "Epoch 25/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8183 - loss: 0.4457 - val_accuracy: 0.7650 - val_loss: 0.5131\n",
            "Epoch 26/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8198 - loss: 0.4375 - val_accuracy: 0.7758 - val_loss: 0.5028\n",
            "Epoch 27/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8372 - loss: 0.4205 - val_accuracy: 0.7733 - val_loss: 0.5034\n",
            "Epoch 28/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8429 - loss: 0.4106 - val_accuracy: 0.7617 - val_loss: 0.5276\n",
            "Epoch 29/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8347 - loss: 0.4180 - val_accuracy: 0.7792 - val_loss: 0.5056\n",
            "Epoch 30/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8310 - loss: 0.4314 - val_accuracy: 0.7758 - val_loss: 0.5092\n",
            "Epoch 31/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8445 - loss: 0.4066 - val_accuracy: 0.7725 - val_loss: 0.5158\n",
            "Epoch 32/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8433 - loss: 0.4031 - val_accuracy: 0.7725 - val_loss: 0.5092\n",
            "Epoch 33/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8543 - loss: 0.3928 - val_accuracy: 0.7742 - val_loss: 0.5085\n",
            "Epoch 34/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8282 - loss: 0.4294 - val_accuracy: 0.7775 - val_loss: 0.5155\n",
            "Epoch 35/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8593 - loss: 0.3812 - val_accuracy: 0.7775 - val_loss: 0.5174\n",
            "Epoch 36/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8564 - loss: 0.3849 - val_accuracy: 0.7833 - val_loss: 0.5145\n",
            "Epoch 37/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8560 - loss: 0.3939 - val_accuracy: 0.7792 - val_loss: 0.5269\n",
            "Epoch 38/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8698 - loss: 0.3667 - val_accuracy: 0.7792 - val_loss: 0.5244\n",
            "Epoch 39/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8622 - loss: 0.3844 - val_accuracy: 0.7775 - val_loss: 0.5300\n",
            "Epoch 40/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8711 - loss: 0.3604 - val_accuracy: 0.7808 - val_loss: 0.5331\n",
            "Epoch 41/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8647 - loss: 0.3777 - val_accuracy: 0.7758 - val_loss: 0.5296\n",
            "Epoch 42/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8716 - loss: 0.3637 - val_accuracy: 0.7825 - val_loss: 0.5285\n",
            "Epoch 43/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8685 - loss: 0.3634 - val_accuracy: 0.7783 - val_loss: 0.5358\n",
            "Epoch 44/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8544 - loss: 0.3955 - val_accuracy: 0.7800 - val_loss: 0.5270\n",
            "Epoch 45/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8823 - loss: 0.3470 - val_accuracy: 0.7817 - val_loss: 0.5270\n",
            "Epoch 46/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8732 - loss: 0.3625 - val_accuracy: 0.7842 - val_loss: 0.5362\n",
            "Epoch 47/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8887 - loss: 0.3376 - val_accuracy: 0.7767 - val_loss: 0.5447\n",
            "Epoch 48/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8888 - loss: 0.3323 - val_accuracy: 0.7850 - val_loss: 0.5379\n",
            "Epoch 49/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8872 - loss: 0.3425 - val_accuracy: 0.7833 - val_loss: 0.5414\n",
            "Epoch 50/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8787 - loss: 0.3543 - val_accuracy: 0.7800 - val_loss: 0.5455\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f19f4a0fc90>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstm_model.fit(train_data,\n",
        "               train_labels,\n",
        "               validation_split=0.20,\n",
        "               batch_size = 50,\n",
        "               epochs = 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUnVMrDkkIFo",
        "outputId": "8973ad7d-80ba-4845-d4d6-d4b3c00f26ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7409 - loss: 0.6175\n",
            "Test accuracy: 74.9 %\n"
          ]
        }
      ],
      "source": [
        "l, a = lstm_model.evaluate(x_test_padded, y_test)\n",
        "print(\"Test accuracy:\", round(a*100,2),\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "zPjr-dfGkTiZ"
      },
      "outputs": [],
      "source": [
        "# Custom function to predict sentences\n",
        "def lstm_predict(sentence:str):\n",
        "  sentence = clean_sentence(sentence)\n",
        "  # Encode sentence\n",
        "  ready_sentence = encode_sentence(sentence)\n",
        "  # Padding sentence\n",
        "  ready_sentence = pad_sequences(sequences = [ready_sentence],\n",
        "                                 maxlen=MAX_SEQ_LEN,\n",
        "                                 dtype='int32',\n",
        "                                 padding='post',\n",
        "                                 truncating='post',\n",
        "                                 value = dummy)\n",
        "\n",
        "  # Predict\n",
        "  prediction = round(lstm_model.predict(ready_sentence)[0][0])\n",
        "  if prediction==0:\n",
        "    print(\"Negative Review\")\n",
        "  elif prediction==1:\n",
        "    print(\"Positive Review\")\n",
        "  else:\n",
        "    print('Error')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPHlPxBFkWEv",
        "outputId": "a3d1a8c9-96a1-4323-f2e8-0f3634515283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "Positive Review\n"
          ]
        }
      ],
      "source": [
        "# Straight forward positive\n",
        "lstm_predict(\"I really recommend this book\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ijlnIBUkdhC",
        "outputId": "dc49f598-9369-4aa5-d3d9-2333093f1f51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "Positive Review\n"
          ]
        }
      ],
      "source": [
        "# Tricky positive\n",
        "lstm_predict(\"The dvd included a big poster of my favorite hero. I just can't wait for the second episode\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWWp4A5Ukf1b",
        "outputId": "fcc6e677-d935-4a08-e2d4-3bd4d4fcb480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Negative Review\n"
          ]
        }
      ],
      "source": [
        "# Straight forward negative\n",
        "lstm_predict(\"I don't know what the hell did i just read, the book is full nonsense\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "isy503-tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
